{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf0owPAgdEaG"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUleu8z8fzQy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import umap\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import trustworthiness\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "import hdbscan\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojsNOdJ_k0Jy"
      },
      "outputs": [],
      "source": [
        "# Get the current working directory\n",
        "current_wd = os.getcwd()\n",
        "\n",
        "# Define paths relative to the base directory\n",
        "data_dir = os.path.join(current_wd, 'Project')\n",
        "iroads_folder = os.path.join(data_dir, 'iROADSDataset')\n",
        "catsvsdogs_folder = os.path.join(data_dir, 'PetImages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5zrVZ4nk2xA",
        "outputId": "f5896437-5922-4c37-ff48-371418895dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4656 files belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "# Set up parameters for the datasets\n",
        "image_height = 224\n",
        "image_width = 224\n",
        "batch_size = 32\n",
        "\n",
        "# Create dataset for iRoads\n",
        "iroads_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=iroads_folder,\n",
        "    image_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    labels=\"inferred\"\n",
        ")\n",
        "\n",
        "#Get rid of corrupt images from catsvsdogs\n",
        "deleted = 0\n",
        "\n",
        "#Loop over the pet_folder\n",
        "for pet_folder in (\"Cat\", \"Dog\"):\n",
        "  #Path to the folder\n",
        "  folder_path = os.path.join(catsvsdogs_folder, pet_folder)\n",
        "  #Loop through each file in folder\n",
        "  for pet_name in os.listdir(folder_path):\n",
        "    #Full path for each image\n",
        "    image_path = os.path.join(folder_path, pet_name)\n",
        "\n",
        "    #Check if the file is a valid JPEG image\n",
        "    try:\n",
        "      x = open(image_path, \"rb\")\n",
        "      valid_jfif = b\"JFIF\" in x.peek(10)\n",
        "    finally:\n",
        "      x.close()\n",
        "\n",
        "    if not valid_jfif:\n",
        "      deleted += 1\n",
        "      os.remove(image_path)\n",
        "print(f\"Number of delete corrupted images {deleted}\")\n",
        "\n",
        "\n",
        "# Create dataset for catsvsdogs\n",
        "catsvsdogs_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=catsvsdogs_folder,\n",
        "    image_size=(image_height,image_width),\n",
        "    batch_size=batch_size,\n",
        "    labels=\"inferred\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx5p-bgqdKyj"
      },
      "source": [
        "**Convert to Numpy Array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEtlEMBik5VI",
        "outputId": "260aa22c-454b-47cf-8734-0cc51555ed1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'iroads_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f2b37cd39a7f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miroad_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miroads_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0miroad_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0miroad_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iroads_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "iroad_images = []\n",
        "iroad_labels = []\n",
        "\n",
        "for image_batch, label_batch in iroads_dataset:\n",
        "  iroad_images.append(image_batch)\n",
        "  iroad_labels.append(label_batch)\n",
        "\n",
        "iroad_images = tf.concat(iroad_images, axis = 0)\n",
        "iroad_labels = tf.concat(iroad_labels, axis = 0)\n",
        "\n",
        "iroad_images = iroad_images.numpy()\n",
        "iroad_labels = iroad_labels.numpy()\n",
        "\n",
        "#Make a copy of the original numpy arrays for the augment images and labels\n",
        "iroad_images_with_augment = np.copy(iroad_images)\n",
        "iroad_labels_with_augment = np.copy(iroad_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR0_uhF2k8K7"
      },
      "outputs": [],
      "source": [
        "catsvsdogs_images = []\n",
        "catsvsdogs_labels = []\n",
        "\n",
        "for image_batch, label_batch in catsvsdogs_dataset:\n",
        "  catsvsdogs_images.append(image_batch)\n",
        "  catsvsdogs_labels.append(label_batch)\n",
        "\n",
        "catsvsdogs_images = tf.concat(catsvsdogs_images, axis=0)\n",
        "catsvsdogs_labels = tf.concat(catsvsdogs_labels, axis=0)\n",
        "\n",
        "catsvsdogs_images = catsvsdogs_images.numpy()\n",
        "catsvsdogs_labels = catsvsdogs_labels.numpy()\n",
        "\n",
        "#Make a copy of the original numpy arrays for the augment images and labels\n",
        "catsvsdogs_images_with_augment = np.copy(catsvsdogs_images)\n",
        "catsvsdogs_labels_with_augment = np.copy(catsvsdogs_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar-8Iw5-kUeW"
      },
      "source": [
        "**Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k2v2KKSOkT_0"
      },
      "outputs": [],
      "source": [
        "#ImageDataGenerator - Augmentation\n",
        "\n",
        "augmented_image_maker = ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.3,\n",
        "    height_shift_range = 0.1,\n",
        "    zoom_range = 0.3,\n",
        "    vertical_flip = True,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = \"nearest\"\n",
        ")\n",
        "\n",
        "#How many images do we want to augment\n",
        "percent = 0.4\n",
        "number_of_images_iroads = int(len(iroad_images) * percent)\n",
        "number_of_images_catsvsdogs = int(len(catsvsdogs_images)*percent)\n",
        "\n",
        "print(number_of_images_iroads)\n",
        "print(number_of_images_catsvsdogs)\n",
        "\n",
        "#Random selection of images in each dataset (ie. the index of the image), that we will augment\n",
        "images_to_augment_iroads = np.random.choice(len(iroad_images), number_of_images_iroads, replace=False)\n",
        "images_to_augment_catsvsdogs = np.random.choice(len(catsvsdogs_images), number_of_images_catsvsdogs, replace=False)\n",
        "\n",
        "print(images_to_augment_iroads)\n",
        "print(images_to_augment_catsvsdogs)\n",
        "\n",
        "#Select those random images, along with there labels\n",
        "selected_iroads_images = iroad_images[images_to_augment_iroads]\n",
        "selected_iroads_labels = iroad_labels[images_to_augment_iroads]\n",
        "\n",
        "selected_catsvsdogs_images = catsvsdogs_images[images_to_augment_catsvsdogs]\n",
        "selected_catsvsdogs_labels = catsvsdogs_labels[images_to_augment_catsvsdogs]\n",
        "\n",
        "#Augment the images and labels\n",
        "augment_iroads = augmented_image_maker.flow(selected_iroads_images, selected_iroads_labels, batch_size=number_of_images_iroads,shuffle=True)\n",
        "augment_catsvsdogs = augmented_image_maker.flow(selected_catsvsdogs_images, selected_catsvsdogs_labels, batch_size=number_of_images_catsvsdogs, shuffle=True)\n",
        "\n",
        "#Return the augmented images and labels\n",
        "augmented_iroad_image, augmented_iroad_label = next(augment_iroads)\n",
        "augmented_cd_image, augmented_cd_label = next(augment_catsvsdogs)\n",
        "\n",
        "#Add the augmented images with the original dataset\n",
        "iroad_images_with_augment[images_to_augment_iroads] = augmented_iroad_image\n",
        "iroad_labels_with_augment[images_to_augment_iroads] = augmented_iroad_label\n",
        "\n",
        "catsvsdogs_images_with_augment[images_to_augment_catsvsdogs] = augmented_cd_image\n",
        "catsvsdogs_labels_with_augment[images_to_augment_catsvsdogs] = augmented_cd_label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnq-i6Kydbi2"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "**Split (Train/Test) -original**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLUzM_x_mZdH"
      },
      "outputs": [],
      "source": [
        "#Split iRoads Original\n",
        "\n",
        "x_trainr, x_testr, y_trainr, y_testr = train_test_split(iroad_images, iroad_labels, test_size=0.2, random_state=23)\n",
        "#Split CatsvsDogs Original\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(catsvsdogs_images, catsvsdogs_labels, test_size=0.2, random_state=23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKuY2GP0hzXv"
      },
      "source": [
        "**Split(Train/Test) - with augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMJRu5i9hvn7"
      },
      "outputs": [],
      "source": [
        "#Split iRoads (with augmentation)\n",
        "\n",
        "x_trainr_a, x_testr_a, y_trainr_a, y_testr_a = train_test_split(augmented_iroad_image, augmented_iroad_label, test_size=0.2, random_state=23)\n",
        "\n",
        "#Split CatsvsDogs (with augmentation)\n",
        "\n",
        "x_train_a, x_test_a, y_train_a, y_test_a = train_test_split(augmented_cd_image, augmented_cd_label, test_size=0.2, random_state=23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOGoZh2xhnyB"
      },
      "source": [
        "**Feature Extraction Resnet50 -original**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jucMCNdVn0Mq"
      },
      "outputs": [],
      "source": [
        "#Feature Extraction -ResNet50\n",
        "\n",
        "#Standard Model\n",
        "standard_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(image_height, image_width, 3))\n",
        "\n",
        "#Freeze Layers\n",
        "for layer in standard_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "#Using the last convolutional block\n",
        "conv5_block3_out = standard_model.get_layer(\"conv5_block3_out\").output\n",
        "\n",
        "# Feature Extractor\n",
        "extractor = Model(inputs = standard_model.input, outputs = conv5_block3_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuyz65FwsPq6"
      },
      "outputs": [],
      "source": [
        "#Preprocess iRoads\n",
        "\n",
        "preprocess_x_train_roads = preprocess_input(x_trainr)\n",
        "preprocess_x_test_roads = preprocess_input(x_testr)\n",
        "\n",
        "#Preprocess CatsvsDogs\n",
        "\n",
        "preprocess_x_train = preprocess_input(x_train)\n",
        "preprocess_x_test = preprocess_input(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Yaj8bNFDw3x4"
      },
      "outputs": [],
      "source": [
        "# Extract Features iRoads\n",
        "features_x_train_roads = extractor.predict(preprocess_x_train_roads)\n",
        "features_x_test_roads = extractor.predict(preprocess_x_test_roads)\n",
        "\n",
        "#Extract Features CatsvsDogs\n",
        "features_x_train = extractor.predict(preprocess_x_train)\n",
        "features_x_test = extractor.predict(preprocess_x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz4jPFpWA9Gj"
      },
      "outputs": [],
      "source": [
        "# Flatten Features iRoads\n",
        "road_train_features = features_x_train_roads.reshape(features_x_train_roads.shape[0], -1)\n",
        "road_test_features = features_x_test_roads.reshape(features_x_test_roads.shape[0],-1)\n",
        "\n",
        "#Flatten Featuers CatsvsDogs\n",
        "train_features = features_x_train.reshape(features_x_train.shape[0], -1)\n",
        "test_features = features_x_test.reshape(features_x_test.shape[0],-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvGzTeAZK8fk"
      },
      "outputs": [],
      "source": [
        "#Scaling Features\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#Scale iRoads\n",
        "road_train_scaled = scaler.fit_transform(road_train_features)\n",
        "road_test_scaled = scaler.fit_transform(road_test_features)\n",
        "\n",
        "#Scale CatsvsDogs\n",
        "catsvsdogs_train_scaled = scaler.fit_transform(train_features)\n",
        "catsvsdogs_test_scaled = scaler.fit_transform(test_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huxCJbcPMO5W"
      },
      "outputs": [],
      "source": [
        "#PCA - explained variance (components)\n",
        "\n",
        "#iRoads\n",
        "pca_roads = PCA(n_components=0.95)\n",
        "pca_roads.fit(road_train_scaled)\n",
        "components_used_roads = pca_roads.n_components_\n",
        "print(components_used_roads)\n",
        "\n",
        "# #CatsvsDogs\n",
        "pca_catsvsdogs = PCA(n_components=0.95)\n",
        "pca_catsvsdogs.fit(catsvsdogs_train_scaled)\n",
        "components_used_catsvsdogs = pca_catsvsdogs.n_components_\n",
        "print(components_used_catsvsdogs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "collapsed": true,
        "id": "occ2hq50NNIt",
        "outputId": "6a8aec49-3f38-4f60-fe4f-ec6b4357de1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f8d109cd7c93>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mumap_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mumap_roads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumap_reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroad_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0miroads_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrustworthiness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroad_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mumap_roads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, force_all_finite, **kwargs)\u001b[0m\n\u001b[1;32m   2926\u001b[0m             \u001b[0mLocal\u001b[0m \u001b[0mradii\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m         \"\"\"\n\u001b[0;32m-> 2928\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2929\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, force_all_finite, **kwargs)\u001b[0m\n\u001b[1;32m   2553\u001b[0m                 \u001b[0;31m# sklearn pairwise_distances fails for callable metric on sparse data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m                 \u001b[0m_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_data\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_distance_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m                 \u001b[0mdmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m                 \u001b[0;31m# metric is numba.jit'd or not supported by sklearn,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2373\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2375\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1893\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1928\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1930\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m         \u001b[0;31m# Make symmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Umap - finding optimal n_components for iRoads\n",
        "\n",
        "iroads_score = {}\n",
        "\n",
        "\n",
        "for i in range (2,6):\n",
        "  for j in range (15,30):\n",
        "    umap_reduction = umap.UMAP(n_components=i, n_neighbors=j)\n",
        "    umap_roads = umap_reduction.fit_transform(road_train_scaled)\n",
        "    iroads_score[(i,j)] = trustworthiness(road_train_scaled,umap_roads,n_neighbors=j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwIB0sao2n9A"
      },
      "outputs": [],
      "source": [
        "#Umap - finding optimal n_components for Cats vs Dogs\n",
        "\n",
        "catsvsdogs_score = {}\n",
        "\n",
        "for i in range(2,6):\n",
        "  for j in range(15,30):\n",
        "    umap_reduction_2 = umap.UMAP(n_components=i, n_neighbors=j)\n",
        "    umap_catsvsdogs = umap_reduction_2.fit_transform(catsvsdogs_train_scaled)\n",
        "    catsvsdogs_score[(i,j)] = trustworthiness(catsvsdogs_train_scaled,umap_catsvsdogs,n_neighbors=j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UII70toU8v0T"
      },
      "outputs": [],
      "source": [
        "# Apply Umap\n",
        "\n",
        "#iRoads Umap\n",
        "umap_1 = umap.UMAP(n_components=3, n_neighbors=15)\n",
        "umap_train_road_results = umap_1.fit_transform(road_train_scaled)\n",
        "umap_test_road_results = umap_1.transform(road_test_scaled)\n",
        "\n",
        "#CatsvsDogs Umap\n",
        "umap_2 = umap.UMAP(n_components=3, n_neighbors=15)\n",
        "umap_catsvsdogs_train_results = umap_2.fit_transform(catsvsdogs_train_scaled)\n",
        "umap_catsvsdogs_test_results = umap_2.transform(catsvsdogs_test_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apx8SicY-cgU"
      },
      "outputs": [],
      "source": [
        "#Visualize Umap\n",
        "\n",
        "#iRoads\n",
        "df_iroads_train = pd.DataFrame({\n",
        "    \"Umap1\": umap_train_road_results[:,0],\n",
        "    \"Umap2\": umap_train_road_results[:,1],\n",
        "    \"Labels\": y_trainr\n",
        "})\n",
        "\n",
        "df_iroads_test = pd.DataFrame({\n",
        "    \"Umap1\":umap_test_road_results[:,0],\n",
        "    \"Umap2\":umap_test_road_results[:,1],\n",
        "    \"Labels\":y_testr\n",
        "})\n",
        "\n",
        "\n",
        "#CatsvsDogs\n",
        "df_catsvsdogs_train = pd.DataFrame({\n",
        "    \"Umap1\":umap_catsvsdogs_train_results[:,0],\n",
        "    \"Umap2\":umap_catsvsdogs_train_results[:,1],\n",
        "    \"Labels\":y_train\n",
        "})\n",
        "\n",
        "df_catsvsdogs_test = pd.DataFrame({\n",
        "    \"Umap1\":umap_catsvsdogs_test_results[:,0],\n",
        "    \"Umap2\":umap_catsvsdogs_test_results[:,1],\n",
        "    \"Labels\":y_test\n",
        "})\n",
        "\n",
        "\n",
        "#Plot iRoads Train\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Labels\",data = df_iroads_train, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Train\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "#Plot iRoads Test\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Labels\",data = df_iroads_test, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Test\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot CatsvsDogs Train\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Labels\",data = df_catsvsdogs_train, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Train\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "#Plot CatsvsDogs Test\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Labels\",data = df_catsvsdogs_test, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Test\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kbVgrL4lRdu"
      },
      "source": [
        "**Feature Extraction Resnet50 (with augmentation)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZYoiJC3lQTF"
      },
      "outputs": [],
      "source": [
        "#Feature Extraction -ResNet50\n",
        "\n",
        "#Standard Model\n",
        "standard_model_with_augmentation = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(image_height, image_width, 3))\n",
        "\n",
        "#Freeze Layers\n",
        "for layer in standard_model_with_augmentation.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "#Using the last convolutional block\n",
        "conv5_block3_out_2 = standard_model_with_augmentation.get_layer(\"conv5_block3_out\").output\n",
        "\n",
        "# Feature Extractor\n",
        "extractor_2 = Model(inputs = standard_model_with_augmentation.input, outputs = conv5_block3_out_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Preprocess iRoads\n",
        "\n",
        "preprocess_x_train_roads_with_augmentation = preprocess_input(x_trainr_a)\n",
        "preprocess_x_test_roads_with_augmentation = preprocess_input(x_testr_a)\n",
        "\n",
        "#Preprocess CatsvsDogs\n",
        "\n",
        "preprocess_x_train_with_augmentation = preprocess_input(x_train_a)\n",
        "preprocess_x_test_with_augmentation = preprocess_input(x_test_a)\n",
        "\n",
        "\n",
        "\n",
        "# Extract Features iRoads\n",
        "features_x_train_roads_with_augmentation = extractor_2.predict(preprocess_x_train_roads_with_augmentation)\n",
        "features_x_test_roads_with_augmentation = extractor_2.predict(preprocess_x_test_roads_with_augmentation)\n",
        "\n",
        "#Extract Features CatsvsDogs\n",
        "features_x_train_with_augmentation = extractor_2.predict(preprocess_x_train_with_augmentation)\n",
        "features_x_test_with_augmentation = extractor_2.predict(preprocess_x_test_with_augmentation)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Flatten Features iRoads\n",
        "road_train_features_with_augmentation = features_x_train_roads_with_augmentation.reshape(features_x_train_roads_with_augmentation.shape[0], -1)\n",
        "road_test_features_with_augmentation = features_x_test_roads_with_augmentation.reshape(features_x_test_roads_with_augmentation.shape[0],-1)\n",
        "\n",
        "#Flatten Featuers CatsvsDogs\n",
        "train_features_with_augmentation = features_x_train_with_augmentation.reshape(features_x_train_with_augmentation.shape[0], -1)\n",
        "test_features_with_augmentation = features_x_test_with_augmentation.reshape(features_x_test_with_augmentation.shape[0],-1)\n",
        "\n",
        "\n",
        "\n",
        "#Scaling Features\n",
        "\n",
        "scaler_2 = StandardScaler()\n",
        "\n",
        "#Scale iRoads\n",
        "road_train_scaled_with_augmentation = scaler_2.fit_transform(road_train_features_with_augmentation)\n",
        "road_test_scaled_with_augmentation = scaler_2.fit_transform(road_test_features_with_augmentation)\n",
        "\n",
        "#Scale CatsvsDogs\n",
        "catsvsdogs_train_scaled_with_augmentation = scaler_2.fit_transform(train_features_with_augmentation)\n",
        "catsvsdogs_test_scaled_with_augmentation = scaler_2.fit_transform(test_features_with_augmentation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy05uQQTvFx-"
      },
      "outputs": [],
      "source": [
        "#PCA - explained variance (components)\n",
        "\n",
        "#iRoads\n",
        "pca_roads_with_augmentation = PCA(n_components=0.95)\n",
        "pca_roads_with_augmentation.fit(road_train_scaled_with_augmentation)\n",
        "components_used_iroads_aug = pca_roads_with_augmentation.n_components_\n",
        "print(components_used_iroads_aug)\n",
        "\n",
        "#CatsvsDogs\n",
        "pca_catsvsdogs_with_augmentation = PCA(n_components=0.95)\n",
        "pca_catsvsdogs_with_augmentation.fit(catsvsdogs_train_scaled_with_augmentation)\n",
        "components_used_catsvsdogs_aug = pca_catsvsdogs_with_augmentation.n_components_\n",
        "print(components_used_catsvsdogs_aug)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GIV3qxdexUXH"
      },
      "outputs": [],
      "source": [
        "#Umap - finding optimal n_components for iRoads\n",
        "\n",
        "iroads_score_with_augmentation = {}\n",
        "\n",
        "\n",
        "for i in range (2,6):\n",
        "  for j in range (15,30):\n",
        "    umap_reduction_2 = umap.UMAP(n_components=i, n_neighbors=j)\n",
        "    umap_roads_2 = umap_reduction_2.fit_transform(road_train_scaled_with_augmentation)\n",
        "    iroads_score_with_augmentation[(i,j)] = trustworthiness(road_train_scaled_with_augmentation,umap_roads_2,n_neighbors=j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4uTPy2KzVhI"
      },
      "outputs": [],
      "source": [
        "#Umap - finding optimal n_components for Cats vs Dogs\n",
        "\n",
        "catsvsdogs_score_with_augmentation = {}\n",
        "\n",
        "for i in range(2,6):\n",
        "  for j in range(15,30):\n",
        "    umap_reduction_3 = umap.UMAP(n_components=i, n_neighbors=j)\n",
        "    umap_catsvsdogs_3 = umap_reduction_3.fit_transform(catsvsdogs_train_scaled_with_augmentation)\n",
        "    catsvsdogs_score_with_augmentation[(i,j)] = trustworthiness(catsvsdogs_train_scaled_with_augmentation,umap_catsvsdogs_3,n_neighbors=j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "keeLmIGl0eVR"
      },
      "outputs": [],
      "source": [
        "# Apply Umap (data with augmentation)\n",
        "\n",
        "#iRoads Umap\n",
        "umap_3 = umap.UMAP(n_components=4, n_neighbors=15)\n",
        "umap_train_road_results_with_augmentation = umap_3.fit_transform(road_train_scaled_with_augmentation)\n",
        "umap_test_road_results_with_augmentation = umap_3.transform(road_test_scaled_with_augmentation)\n",
        "\n",
        "#CatsvsDogs Umap\n",
        "umap_4 = umap.UMAP(n_components=4, n_neighbors=15)\n",
        "umap_catsvsdogs_train_results_with_augmentation = umap_4.fit_transform(catsvsdogs_train_scaled_with_augmentation)\n",
        "umap_catsvsdogs_test_results_with_augmentation = umap_4.transform(catsvsdogs_test_scaled_with_augmentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ouLj5ysT5FYh"
      },
      "outputs": [],
      "source": [
        "#Visualize Umap\n",
        "\n",
        "#iRoads\n",
        "df_iroads_train_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\": umap_train_road_results_with_augmentation[:,0],\n",
        "    \"Umap2\": umap_train_road_results_with_augmentation[:,1],\n",
        "    \"Labels\": y_trainr_a\n",
        "})\n",
        "\n",
        "df_iroads_test_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\":umap_test_road_results_with_augmentation[:,0],\n",
        "    \"Umap2\":umap_test_road_results_with_augmentation[:,1],\n",
        "    \"Labels\":y_testr_a\n",
        "})\n",
        "\n",
        "\n",
        "#CatsvsDogs\n",
        "df_catsvsdogs_train_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\":umap_catsvsdogs_train_results_with_augmentation[:,0],\n",
        "    \"Umap2\":umap_catsvsdogs_train_results_with_augmentation[:,1],\n",
        "    \"Labels\":y_train_a\n",
        "})\n",
        "\n",
        "df_catsvsdogs_test_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\":umap_catsvsdogs_test_results_with_augmentation[:,0],\n",
        "    \"Umap2\":umap_catsvsdogs_test_results_with_augmentation[:,1],\n",
        "    \"Labels\":y_test_a\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "#Plot iRoads Train\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Labels\",data = df_iroads_train_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Train w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "#Plot iRoads Test\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Labels\",data = df_iroads_test_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Test w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot CatsvsDogs Train\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Labels\",data = df_catsvsdogs_train_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Train w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "#Plot CatsvsDogs Test\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Labels\",data = df_catsvsdogs_test_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Test w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTZYzIuldsGy"
      },
      "source": [
        "**CLUSTERING - (original)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WHlx0-_wmPv"
      },
      "outputs": [],
      "source": [
        "#Clustering\n",
        "\n",
        "#iRoads HDBSCAN -Finding the best silhouette score, given certain value parameters\n",
        "\n",
        "\n",
        "#iRoads -Train\n",
        "\n",
        "iroads_train_min_cs = []\n",
        "iroads_train_min_s = []\n",
        "iroads_silscore_training = []\n",
        "\n",
        "for x in range(2,31):\n",
        "  iroads_train_min_cs.append(x)\n",
        "  iroads_train_min_s.append(x)\n",
        "\n",
        "\n",
        "for i in iroads_train_min_cs:\n",
        "  for j in iroads_train_min_s:\n",
        "    h_dbscan = hdbscan.HDBSCAN(min_cluster_size =i, min_samples =j)\n",
        "    h_dbscan_results = h_dbscan.fit_predict(umap_train_road_results)\n",
        "    if np.any(h_dbscan_results != -1):\n",
        "      iroads_train_score = silhouette_score(umap_train_road_results,h_dbscan_results)\n",
        "      iroads_silscore_training.append((i,j,iroads_train_score))\n",
        "\n",
        "\n",
        "#iRoads Test\n",
        "iroads_test_min_cs = []\n",
        "iroads_test_min_s = []\n",
        "iroads_silscore_test = []\n",
        "\n",
        "for x in range(2,31):\n",
        "  iroads_test_min_cs.append(x)\n",
        "  iroads_test_min_s.append(x)\n",
        "\n",
        "for i in iroads_test_min_cs:\n",
        "  for j in iroads_test_min_s:\n",
        "    h_dbscan2 = hdbscan.HDBSCAN(min_cluster_size =i, min_samples =j)\n",
        "    h_dbscan2_results = h_dbscan.fit_predict(umap_test_road_results)\n",
        "    if np.any(h_dbscan2_results != -1):\n",
        "      iroads_test_score = silhouette_score(umap_test_road_results,h_dbscan2_results)\n",
        "      iroads_silscore_test.append((i,j,iroads_test_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmP8udE1JyZu"
      },
      "outputs": [],
      "source": [
        "# Get and Print the best score\n",
        "best_train = max(iroads_silscore_training,key = lambda x: x[2])\n",
        "best_test = max(iroads_silscore_test, key= lambda x: x[2])\n",
        "\n",
        "print(best_train)\n",
        "print(best_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOWGv8M6C9LR"
      },
      "outputs": [],
      "source": [
        "#Clustering\n",
        "\n",
        "#CatsvsDogs HDBSCAN -Finding the best silhouette score, given certain value parameters\n",
        "\n",
        "\n",
        "#CatsvsDogs -Train\n",
        "\n",
        "cd_train_min_cs = []\n",
        "cd_train_min_s = []\n",
        "cd_silscore_training = []\n",
        "\n",
        "for x in range(2,31):\n",
        "  cd_train_min_cs.append(x)\n",
        "  cd_train_min_s.append(x)\n",
        "\n",
        "\n",
        "for i in cd_train_min_cs:\n",
        "  for j in cd_train_min_s:\n",
        "    h_dbscan3 = hdbscan.HDBSCAN(min_cluster_size = i, min_samples=j)\n",
        "    h_dbscan3_results = h_dbscan3.fit_predict(umap_catsvsdogs_train_results)\n",
        "    if np.any(h_dbscan3_results != -1):\n",
        "      cd_train_score = silhouette_score(umap_catsvsdogs_train_results,h_dbscan3_results)\n",
        "      cd_silscore_training.append((i,j,cd_train_score))\n",
        "\n",
        "\n",
        "#CatsvsDogs -Test\n",
        "cd_test_min_cs = []\n",
        "cd_test_min_s = []\n",
        "cd_silscore_test = []\n",
        "\n",
        "for x in range(2,31):\n",
        "  cd_test_min_cs.append(x)\n",
        "  cd_test_min_s.append(x)\n",
        "\n",
        "for i in cd_test_min_cs:\n",
        "  for j in cd_test_min_s:\n",
        "    h_dbscan4 = hdbscan.HDBSCAN(min_cluster_size = i, min_samples=j)\n",
        "    h_dbscan4_results = h_dbscan4.fit_predict(umap_catsvsdogs_test_results)\n",
        "    if np.any(h_dbscan4_results != -1):\n",
        "      cd_test_score = silhouette_score(umap_catsvsdogs_test_results,h_dbscan4_results)\n",
        "      cd_silscore_test.append((i,j,cd_test_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oThTO2XZMvs3"
      },
      "outputs": [],
      "source": [
        "# Get and Print the best score\n",
        "\n",
        "best_train_1 = max(cd_silscore_training,key = lambda x: x[2])\n",
        "best_test_1 = max(cd_silscore_test, key= lambda x: x[2])\n",
        "\n",
        "print(best_train_1)\n",
        "print(best_test_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KkmNmpZGEIR"
      },
      "outputs": [],
      "source": [
        "#Apply Clustering HDBSCAN\n",
        "\n",
        "#iRoads\n",
        "\n",
        "clustering_1 = hdbscan.HDBSCAN(min_cluster_size = 20, min_samples =10)\n",
        "clustering_1_results = clustering_1.fit_predict(umap_train_road_results)\n",
        "\n",
        "df_clustering_1 = pd.DataFrame({\n",
        "    \"Umap1\": umap_train_road_results[:,0],\n",
        "    \"Umap2\": umap_train_road_results[:,1],\n",
        "    \"Cluster\": clustering_1_results\n",
        "})\n",
        "\n",
        "\n",
        "clustering_2 = hdbscan.HDBSCAN(min_cluster_size = 2, min_samples =2)\n",
        "clustering_2_results = clustering_1.fit_predict(umap_test_road_results)\n",
        "\n",
        "\n",
        "df_clustering_2 = pd.DataFrame({\n",
        "    \"Umap1\":umap_test_road_results[:,0],\n",
        "    \"Umap2\":umap_test_road_results[:,1],\n",
        "    \"Cluster\":clustering_2_results\n",
        "})\n",
        "\n",
        "\n",
        "#Cats vs Dogs\n",
        "clustering_3 = hdbscan.HDBSCAN(min_cluster_size =2 , min_samples =30)\n",
        "clustering_3_results = clustering_1.fit_predict(umap_catsvsdogs_train_results)\n",
        "\n",
        "df_clustering_3 = pd.DataFrame({\n",
        "    \"Umap1\":umap_catsvsdogs_train_results[:,0],\n",
        "    \"Umap2\":umap_catsvsdogs_train_results[:,1],\n",
        "    \"Cluster\":clustering_3_results\n",
        "})\n",
        "\n",
        "\n",
        "clustering_4 = hdbscan.HDBSCAN(min_cluster_size =28 , min_samples =2)\n",
        "clustering_4_results = clustering_1.fit_predict(umap_catsvsdogs_test_results)\n",
        "\n",
        "\n",
        "df_clustering_4 = pd.DataFrame({\n",
        "    \"Umap1\":umap_catsvsdogs_test_results[:,0],\n",
        "    \"Umap2\":umap_catsvsdogs_test_results[:,1],\n",
        "    \"Cluster\":clustering_4_results\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKkhDxiFPgvP"
      },
      "outputs": [],
      "source": [
        "#Visualize Clusters\n",
        "\n",
        "#Plot iRoads Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_clustering_1, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Train Clusters\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot iRoads Test\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_clustering_2, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Test Clusters\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot Cats vs Dogs Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_clustering_3, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Train Clusters\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot Cats vs Dogs Test\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_clustering_4, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Test Clusters\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiAaq5ugboVp"
      },
      "outputs": [],
      "source": [
        "#Clustering\n",
        "\n",
        "#iRoads AggClus -Finding the best silhouette score, given certain value of n_clusters\n",
        "\n",
        "#iRoads Train\n",
        "\n",
        "n_cluster_train = []\n",
        "n_cluster_train_silscore = []\n",
        "\n",
        "for x in range(2,21):\n",
        "  n_cluster_train.append(x)\n",
        "\n",
        "for i in n_cluster_train:\n",
        "  aggcluster = AgglomerativeClustering(n_clusters=i)\n",
        "  aggcluster_results = aggcluster.fit_predict(umap_train_road_results)\n",
        "  aggcluster_score = silhouette_score(umap_train_road_results,aggcluster_results)\n",
        "  n_cluster_train_silscore.append((i, aggcluster_score))\n",
        "\n",
        "\n",
        "#iRoads Test\n",
        "n_cluster_test = []\n",
        "n_cluster_test_silscore =[]\n",
        "\n",
        "for x in range(2,21):\n",
        "  n_cluster_test.append(x)\n",
        "\n",
        "for i in n_cluster_test:\n",
        "  aggcluster_1 = AgglomerativeClustering(n_clusters=i)\n",
        "  aggcluster_results_1 = aggcluster.fit_predict(umap_test_road_results)\n",
        "  aggcluster_score_1 = silhouette_score(umap_test_road_results,aggcluster_results_1)\n",
        "  n_cluster_test_silscore.append((i, aggcluster_score_1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdj7gAsTun6r"
      },
      "outputs": [],
      "source": [
        "# Get and Print the best score/with number of clusters\n",
        "\n",
        "top_cluster_train = max(n_cluster_train_silscore, key = lambda x: x[1])\n",
        "top_cluster_test = max(n_cluster_test_silscore, key = lambda x: x[1])\n",
        "print(top_cluster_train)\n",
        "print(top_cluster_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcqr3KLxvOOa"
      },
      "outputs": [],
      "source": [
        "#Clustering\n",
        "\n",
        "#CatsvsDogs AggClus -Finding the best silhouette score, given certain value of n_clusters\n",
        "\n",
        "#CatsvsDogs Train\n",
        "\n",
        "n_cluster_train_1 = []\n",
        "n_cluster_train_silscore_1 = []\n",
        "\n",
        "for x in range(2,21):\n",
        "  n_cluster_train_1.append(x)\n",
        "\n",
        "for i in n_cluster_train:\n",
        "  aggcluster_2 = AgglomerativeClustering(n_clusters=i)\n",
        "  aggcluster_results_2 = aggcluster.fit_predict(umap_catsvsdogs_train_results)\n",
        "  aggcluster_score_2 = silhouette_score(umap_catsvsdogs_train_results,aggcluster_results_2)\n",
        "  n_cluster_train_silscore_1.append((i, aggcluster_score_2))\n",
        "\n",
        "#CatsvsDogs Test\n",
        "\n",
        "n_cluster_test_1 = []\n",
        "n_cluster_test_silscore_1 =[]\n",
        "\n",
        "for x in range(2,21):\n",
        "  n_cluster_test_1.append(x)\n",
        "\n",
        "for i in n_cluster_test:\n",
        "  aggcluster_3 = AgglomerativeClustering(n_clusters=i)\n",
        "  aggcluster_results_3 = aggcluster.fit_predict(umap_catsvsdogs_test_results)\n",
        "  aggcluster_score_3 = silhouette_score(umap_catsvsdogs_test_results,aggcluster_results_3)\n",
        "  n_cluster_test_silscore_1.append((i, aggcluster_score_3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7MebAX_wVZu"
      },
      "outputs": [],
      "source": [
        "top_cluster_train_1 = max(n_cluster_train_silscore_1, key = lambda x: x[1])\n",
        "top_cluster_test_1 = max(n_cluster_test_silscore_1, key = lambda x: x[1])\n",
        "print(top_cluster_train_1)\n",
        "print(top_cluster_test_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZWEzWiswsS5"
      },
      "outputs": [],
      "source": [
        "#Apply Clustering - Agglomerative Clustering\n",
        "\n",
        "#iRoads\n",
        "\n",
        "algo_1 = AgglomerativeClustering(n_clusters=14)\n",
        "algo_1_results = algo_1.fit_predict(umap_train_road_results)\n",
        "\n",
        "df_algo_1 = pd.DataFrame({\n",
        "    \"Umap1\": umap_train_road_results[:,0],\n",
        "    \"Umap2\": umap_train_road_results[:,1],\n",
        "    \"Cluster\": algo_1_results\n",
        "})\n",
        "\n",
        "\n",
        "algo_2 = AgglomerativeClustering(n_clusters=2)\n",
        "algo_2_results = algo_2.fit_predict(umap_test_road_results)\n",
        "\n",
        "df_algo_2 = pd.DataFrame({\n",
        "    \"Umap1\": umap_test_road_results[:,0],\n",
        "    \"Umap2\": umap_test_road_results[:,1],\n",
        "    \"Cluster\": algo_2_results\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "#Cats Vs Dogs\n",
        "\n",
        "algo_3 = AgglomerativeClustering(n_clusters=2)\n",
        "algo_3_results = algo_3.fit_predict(umap_catsvsdogs_train_results)\n",
        "\n",
        "df_algo_3 = pd.DataFrame({\n",
        "    \"Umap1\": umap_catsvsdogs_train_results[:,0],\n",
        "    \"Umap2\": umap_catsvsdogs_train_results[:,1],\n",
        "    \"Cluster\": algo_3_results\n",
        "})\n",
        "\n",
        "\n",
        "algo_4 = AgglomerativeClustering(n_clusters=2)\n",
        "algo_4_results = algo_4.fit_predict(umap_catsvsdogs_test_results)\n",
        "\n",
        "df_algo_4 = pd.DataFrame({\n",
        "    \"Umap1\": umap_catsvsdogs_test_results[:,0],\n",
        "    \"Umap2\": umap_catsvsdogs_test_results[:,1],\n",
        "    \"Cluster\": algo_4_results\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RYkrjsZK0AKV"
      },
      "outputs": [],
      "source": [
        "#Visualize Clusters\n",
        "\n",
        "#Plot iRoads Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_algo_1, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Train Clusters\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "#Plot iRoads Test\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_algo_2, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Test Clusters\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot CatsvsDogs Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_algo_3, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Train Clusters\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot CatsvsDogs Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_algo_4, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Test Clusters\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEiYLE3V0PH3"
      },
      "outputs": [],
      "source": [
        "#Evaluate the quality of Clusters - Davies-Bouldin\n",
        "\n",
        "#iRoads HDBSCAN\n",
        "db_1 = davies_bouldin_score(umap_train_road_results,clustering_1_results)\n",
        "db_2 = davies_bouldin_score(umap_test_road_results,clustering_2_results)\n",
        "\n",
        "#Cats vs Dogs HDBSCAN\n",
        "db_3 = davies_bouldin_score(umap_catsvsdogs_train_results,clustering_3_results)\n",
        "db_4 = davies_bouldin_score(umap_catsvsdogs_test_results,clustering_4_results)\n",
        "\n",
        "\n",
        "#iRoads Agglomerative\n",
        "db_5 = davies_bouldin_score(umap_train_road_results,algo_1_results)\n",
        "db_6 = davies_bouldin_score(umap_test_road_results,algo_2_results)\n",
        "\n",
        "#Cats vs Dogs Agglomerative\n",
        "db_7 = davies_bouldin_score(umap_catsvsdogs_train_results,algo_3_results)\n",
        "db_8 = davies_bouldin_score(umap_catsvsdogs_test_results,algo_4_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOe7s0Au25uw"
      },
      "outputs": [],
      "source": [
        "#Print Davis-Bouldin Values\n",
        "\n",
        "print(f\"HDBSCAN: iRoads train {db_1}, test {db_2},  CatsvsDogs train {db_3}, test {db_4}\")\n",
        "print(f\"Agglomerative : iRoads train {db_5}, test {db_6}, CatsvsDogs train {db_7}, test {db_8}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqmB2AHBKmZv"
      },
      "source": [
        "Clustering -(with augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3FZVFy_KmET"
      },
      "outputs": [],
      "source": [
        "#Clustering (augmented data)\n",
        "\n",
        "#iRoads HDBSCAN -Finding the best silhouette score, given certain value parameters\n",
        "\n",
        "\n",
        "#iRoads -Train\n",
        "\n",
        "iroads_train_min_cs_with_augmentation = []\n",
        "iroads_train_min_s_with_augmentation = []\n",
        "iroads_silscore_training_with_augmentation = []\n",
        "\n",
        "for x in range(2,31):\n",
        "  iroads_train_min_cs_with_augmentation.append(x)\n",
        "  iroads_train_min_s_with_augmentation.append(x)\n",
        "\n",
        "\n",
        "for i in iroads_train_min_cs_with_augmentation:\n",
        "  for j in iroads_train_min_s_with_augmentation:\n",
        "    h_dbscan_with_augmentation = hdbscan.HDBSCAN(min_cluster_size =i, min_samples =j)\n",
        "    h_dbscan_results_with_augmentation = h_dbscan_with_augmentation.fit_predict(umap_train_road_results_with_augmentation)\n",
        "    if np.any(h_dbscan_results_with_augmentation != -1):\n",
        "      iroads_train_score_with_augmentation = silhouette_score(umap_train_road_results_with_augmentation,h_dbscan_results_with_augmentation)\n",
        "      iroads_silscore_training_with_augmentation.append((i,j,iroads_train_score_with_augmentation))\n",
        "\n",
        "\n",
        "#iRoads Test\n",
        "iroads_test_min_cs_with_augmentation = []\n",
        "iroads_test_min_s_with_augmentation = []\n",
        "iroads_silscore_test_with_augmentation = []\n",
        "\n",
        "for x in range(2,31):\n",
        "  iroads_test_min_cs_with_augmentation.append(x)\n",
        "  iroads_test_min_s_with_augmentation.append(x)\n",
        "\n",
        "for i in iroads_test_min_cs_with_augmentation:\n",
        "  for j in iroads_test_min_s_with_augmentation:\n",
        "    h_dbscan2_with_augmentation = hdbscan.HDBSCAN(min_cluster_size =i, min_samples =j)\n",
        "    h_dbscan2_results_with_augmentation = h_dbscan2_with_augmentation.fit_predict(umap_test_road_results_with_augmentation)\n",
        "    if np.any(h_dbscan2_results_with_augmentation != -1):\n",
        "      iroads_test_score_with_augmentation = silhouette_score(umap_test_road_results_with_augmentation,h_dbscan2_results_with_augmentation)\n",
        "      iroads_silscore_test_with_augmentation.append((i,j,iroads_test_score_with_augmentation))\n",
        "\n",
        "\n",
        "# Get and Print the best score\n",
        "best_train_with_augmentation = max(iroads_silscore_training_with_augmentation,key = lambda x: x[2])\n",
        "best_test_with_augmentation = max(iroads_silscore_test_with_augmentation, key= lambda x: x[2])\n",
        "\n",
        "print(best_train_with_augmentation)\n",
        "print(best_test_with_augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJOAaWz4KlIs"
      },
      "outputs": [],
      "source": [
        "#Clustering (with augmentation)\n",
        "\n",
        "#CatsvsDogs HDBSCAN -Finding the best silhouette score, given certain value parameters\n",
        "\n",
        "\n",
        "#CatsvsDogs -Train\n",
        "\n",
        "cd_train_min_cs_with_augmentation = []\n",
        "cd_train_min_s_with_augmentation = []\n",
        "cd_silscore_training_with_augmentation = []\n",
        "\n",
        "for x in range(2,31):\n",
        "  cd_train_min_cs_with_augmentation.append(x)\n",
        "  cd_train_min_s_with_augmentation.append(x)\n",
        "\n",
        "\n",
        "for i in cd_train_min_cs_with_augmentation:\n",
        "  for j in cd_train_min_s_with_augmentation:\n",
        "    h_dbscan3_with_augmentation = hdbscan.HDBSCAN(min_cluster_size = i, min_samples=j)\n",
        "    h_dbscan3_results_with_augmentation = h_dbscan3_with_augmentation.fit_predict(umap_catsvsdogs_train_results_with_augmentation)\n",
        "    if np.any(h_dbscan3_results_with_augmentation != -1):\n",
        "      cd_train_score_with_augmentation = silhouette_score(umap_catsvsdogs_train_results_with_augmentation,h_dbscan3_results_with_augmentation)\n",
        "      cd_silscore_training_with_augmentation.append((i,j,cd_train_score_with_augmentation))\n",
        "\n",
        "\n",
        "#CatsvsDogs -Test\n",
        "cd_test_min_cs_with_augmentation = []\n",
        "cd_test_min_s_with_augmentation = []\n",
        "cd_silscore_test_with_augmentation = []\n",
        "\n",
        "for x in range(2,31):\n",
        "  cd_test_min_cs_with_augmentation.append(x)\n",
        "  cd_test_min_s_with_augmentation.append(x)\n",
        "\n",
        "for i in cd_test_min_cs_with_augmentation:\n",
        "  for j in cd_test_min_s_with_augmentation:\n",
        "    h_dbscan4_with_augmentation = hdbscan.HDBSCAN(min_cluster_size = i, min_samples=j)\n",
        "    h_dbscan4_results_with_augmentation = h_dbscan4_with_augmentation.fit_predict(umap_catsvsdogs_test_results_with_augmentation)\n",
        "    if np.any(h_dbscan4_results_with_augmentation != -1):\n",
        "      cd_test_score_with_augmentation = silhouette_score(umap_catsvsdogs_test_results_with_augmentation,h_dbscan4_results_with_augmentation)\n",
        "      cd_silscore_test_with_augmentation.append((i,j,cd_test_score_with_augmentation))\n",
        "\n",
        "# Get the best score\n",
        "\n",
        "best_train_1_with_augmentation = max(cd_silscore_training_with_augmentation,key = lambda x: x[2])\n",
        "best_test_1_with_augmentation = max(cd_silscore_test_with_augmentation, key= lambda x: x[2])\n",
        "\n",
        "print(best_train_1_with_augmentation)\n",
        "print(best_test_1_with_augmentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmeZgsnTizMU"
      },
      "outputs": [],
      "source": [
        "#Apply Clustering HDBSCAN _with_augmentation\n",
        "\n",
        "#iRoads\n",
        "\n",
        "clustering_1_with_augmentation = hdbscan.HDBSCAN(min_cluster_size = 2, min_samples =2)\n",
        "clustering_1_results_with_augmentation = clustering_1_with_augmentation.fit_predict(umap_train_road_results_with_augmentation)\n",
        "\n",
        "df_clustering_1_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\": umap_train_road_results_with_augmentation[:,0],\n",
        "    \"Umap2\": umap_train_road_results_with_augmentation[:,1],\n",
        "    \"Cluster\": clustering_1_results_with_augmentation\n",
        "})\n",
        "\n",
        "\n",
        "clustering_2_with_augmentation = hdbscan.HDBSCAN(min_cluster_size = 11, min_samples =2)\n",
        "clustering_2_results_with_augmentation = clustering_2_with_augmentation.fit_predict(umap_test_road_results_with_augmentation)\n",
        "\n",
        "\n",
        "df_clustering_2_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\":umap_test_road_results_with_augmentation[:,0],\n",
        "    \"Umap2\":umap_test_road_results_with_augmentation[:,1],\n",
        "    \"Cluster\":clustering_2_results_with_augmentation\n",
        "})\n",
        "\n",
        "\n",
        "#Cats vs Dogs\n",
        "clustering_3_with_augmentation = hdbscan.HDBSCAN(min_cluster_size =2 , min_samples =30)\n",
        "clustering_3_results_with_augmentation = clustering_3_with_augmentation.fit_predict(umap_catsvsdogs_train_results_with_augmentation)\n",
        "\n",
        "df_clustering_3_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\":umap_catsvsdogs_train_results_with_augmentation[:,0],\n",
        "    \"Umap2\":umap_catsvsdogs_train_results_with_augmentation[:,1],\n",
        "    \"Cluster\":clustering_3_results_with_augmentation\n",
        "})\n",
        "\n",
        "\n",
        "clustering_4_with_augmentation = hdbscan.HDBSCAN(min_cluster_size =28 , min_samples =2)\n",
        "clustering_4_results_with_augmentation = clustering_4_with_augmentation.fit_predict(umap_catsvsdogs_test_results_with_augmentation)\n",
        "\n",
        "\n",
        "df_clustering_4_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\":umap_catsvsdogs_test_results_with_augmentation[:,0],\n",
        "    \"Umap2\":umap_catsvsdogs_test_results_with_augmentation[:,1],\n",
        "    \"Cluster\":clustering_4_results_with_augmentation\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBdzG5UQjouD"
      },
      "outputs": [],
      "source": [
        "#Visualize Clusters\n",
        "\n",
        "#Plot iRoads Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_clustering_1_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Train Clusters w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot iRoads Test\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_clustering_2_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Test Clusters w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot Cats vs Dogs Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_clustering_3_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Train Clusters wa Agmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot Cats vs Dogs Test\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_clustering_4_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Test Clusters w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y96zgrJ5jumj"
      },
      "outputs": [],
      "source": [
        "#Clustering _with_augmentation\n",
        "\n",
        "#iRoads AggClus -Finding the best silhouette score, given certain value of n_clusters\n",
        "\n",
        "#iRoads Train\n",
        "\n",
        "n_cluster_train_with_augmentation = []\n",
        "n_cluster_train_silscore_with_augmentation = []\n",
        "\n",
        "for x in range(2,21):\n",
        "  n_cluster_train_with_augmentation.append(x)\n",
        "\n",
        "for i in n_cluster_train_with_augmentation:\n",
        "  aggcluster_with_augmentation = AgglomerativeClustering(n_clusters=i)\n",
        "  aggcluster_results_with_augmentation = aggcluster_with_augmentation.fit_predict(umap_train_road_results_with_augmentation)\n",
        "  aggcluster_score_with_augmentation = silhouette_score(umap_train_road_results_with_augmentation,aggcluster_results_with_augmentation)\n",
        "  n_cluster_train_silscore_with_augmentation.append((i, aggcluster_score_with_augmentation))\n",
        "\n",
        "\n",
        "#iRoads Test\n",
        "n_cluster_test_with_augmentation = []\n",
        "n_cluster_test_silscore_with_augmentation =[]\n",
        "\n",
        "for x in range(2,21):\n",
        "  n_cluster_test_with_augmentation.append(x)\n",
        "\n",
        "for i in n_cluster_test_with_augmentation:\n",
        "  aggcluster_1_with_augmentation = AgglomerativeClustering(n_clusters=i)\n",
        "  aggcluster_results_1_with_augmentation = aggcluster_with_augmentation.fit_predict(umap_test_road_results_with_augmentation)\n",
        "  aggcluster_score_1_with_augmentation = silhouette_score(umap_test_road_results_with_augmentation,aggcluster_results_1_with_augmentation)\n",
        "  n_cluster_test_silscore_with_augmentation.append((i, aggcluster_score_1_with_augmentation))\n",
        "\n",
        "\n",
        "# Get the best score/with number of clusters\n",
        "\n",
        "top_cluster_train_with_augmentation = max(n_cluster_train_silscore_with_augmentation, key = lambda x: x[1])\n",
        "top_cluster_test_with_augmentation = max(n_cluster_test_silscore_with_augmentation, key = lambda x: x[1])\n",
        "print(top_cluster_train_with_augmentation)\n",
        "print(top_cluster_test_with_augmentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx9jdSkXju2g"
      },
      "outputs": [],
      "source": [
        "#Clustering\n",
        "\n",
        "#CatsvsDogs AggClus -Finding the best silhouette score, given certain value of n_clusters\n",
        "\n",
        "#CatsvsDogs Train\n",
        "\n",
        "n_cluster_train_1_with_augmentation = []\n",
        "n_cluster_train_silscore_1_with_augmentation = []\n",
        "\n",
        "for x in range(2,21):\n",
        "  n_cluster_train_1_with_augmentation.append(x)\n",
        "\n",
        "for i in n_cluster_train_with_augmentation:\n",
        "  aggcluster_2_with_augmentation = AgglomerativeClustering(n_clusters=i)\n",
        "  aggcluster_results_2_with_augmentation = aggcluster_with_augmentation.fit_predict(umap_catsvsdogs_train_results_with_augmentation)\n",
        "  aggcluster_score_2_with_augmentation = silhouette_score(umap_catsvsdogs_train_results_with_augmentation,aggcluster_results_2_with_augmentation)\n",
        "  n_cluster_train_silscore_1_with_augmentation.append((i, aggcluster_score_2_with_augmentation))\n",
        "\n",
        "#CatsvsDogs Test\n",
        "\n",
        "n_cluster_test_1_with_augmentation = []\n",
        "n_cluster_test_silscore_1_with_augmentation =[]\n",
        "\n",
        "for x in range(2,21):\n",
        "  n_cluster_test_1_with_augmentation.append(x)\n",
        "\n",
        "for i in n_cluster_test_with_augmentation:\n",
        "  aggcluster_3_with_augmentation = AgglomerativeClustering(n_clusters=i)\n",
        "  aggcluster_results_3_with_augmentation = aggcluster_with_augmentation.fit_predict(umap_catsvsdogs_test_results_with_augmentation)\n",
        "  aggcluster_score_3_with_augmentation = silhouette_score(umap_catsvsdogs_test_results_with_augmentation,aggcluster_results_3_with_augmentation)\n",
        "  n_cluster_test_silscore_1_with_augmentation.append((i, aggcluster_score_3_with_augmentation))\n",
        "\n",
        "\n",
        "# Get the best score/with number of clusters\n",
        "top_cluster_train_1_with_augmentation = max(n_cluster_train_silscore_1_with_augmentation, key = lambda x: x[1])\n",
        "top_cluster_test_1_with_augmentation = max(n_cluster_test_silscore_1_with_augmentation, key = lambda x: x[1])\n",
        "print(top_cluster_train_1_with_augmentation)\n",
        "print(top_cluster_test_1_with_augmentation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2ntPZA3jvEo"
      },
      "outputs": [],
      "source": [
        "#Apply Clustering - Agglomerative Clustering\n",
        "\n",
        "#iRoads\n",
        "\n",
        "algo_1_with_augmentation = AgglomerativeClustering(n_clusters=2)\n",
        "algo_1_results_with_augmentation = algo_1_with_augmentation.fit_predict(umap_train_road_results_with_augmentation)\n",
        "\n",
        "df_algo_1_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\": umap_train_road_results_with_augmentation[:,0],\n",
        "    \"Umap2\": umap_train_road_results_with_augmentation[:,1],\n",
        "    \"Cluster\": algo_1_results_with_augmentation\n",
        "})\n",
        "\n",
        "\n",
        "algo_2_with_augmentation = AgglomerativeClustering(n_clusters=2)\n",
        "algo_2_results_with_augmentation = algo_2_with_augmentation.fit_predict(umap_test_road_results_with_augmentation)\n",
        "\n",
        "df_algo_2_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\": umap_test_road_results_with_augmentation[:,0],\n",
        "    \"Umap2\": umap_test_road_results_with_augmentation[:,1],\n",
        "    \"Cluster\": algo_2_results_with_augmentation\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "#Cats Vs Dogs\n",
        "\n",
        "algo_3_with_augmentation = AgglomerativeClustering(n_clusters=2)\n",
        "algo_3_results_with_augmentation = algo_3_with_augmentation.fit_predict(umap_catsvsdogs_train_results_with_augmentation)\n",
        "\n",
        "df_algo_3_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\": umap_catsvsdogs_train_results_with_augmentation[:,0],\n",
        "    \"Umap2\": umap_catsvsdogs_train_results_with_augmentation[:,1],\n",
        "    \"Cluster\": algo_3_results_with_augmentation\n",
        "})\n",
        "\n",
        "\n",
        "algo_4_with_augmentation = AgglomerativeClustering(n_clusters=2)\n",
        "algo_4_results_with_augmentation = algo_4_with_augmentation.fit_predict(umap_catsvsdogs_test_results_with_augmentation)\n",
        "\n",
        "df_algo_4_with_augmentation = pd.DataFrame({\n",
        "    \"Umap1\": umap_catsvsdogs_test_results_with_augmentation[:,0],\n",
        "    \"Umap2\": umap_catsvsdogs_test_results_with_augmentation[:,1],\n",
        "    \"Cluster\": algo_4_results_with_augmentation\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DzZ5_X4jvNu"
      },
      "outputs": [],
      "source": [
        "#Visualize Clusters\n",
        "\n",
        "#Plot iRoads Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_algo_1_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Train Clusters w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "#Plot iRoads Test\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_algo_2_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"iRoads Test Clusters w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot CatsvsDogs Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_algo_3_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Train Clusters w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plot CatsvsDogs Train\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x=\"Umap1\", y=\"Umap2\", hue = \"Cluster\",data = df_algo_4_with_augmentation, palette =\"viridis\", s=100, markers=\"o\")\n",
        "plt.title(\"Cats vs Dogs Test Clusters w Augmentation\")\n",
        "plt.xlabel(\"Umap1\")\n",
        "plt.ylabel(\"Umap2\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ytIKnrrjvQt"
      },
      "outputs": [],
      "source": [
        "#Evaluate the quality of Clusters - Davies-Bouldin\n",
        "\n",
        "#iRoads HDBSCAN\n",
        "db_1_with_augmentation = davies_bouldin_score(umap_train_road_results_with_augmentation,clustering_1_results_with_augmentation)\n",
        "db_2_with_augmentation = davies_bouldin_score(umap_test_road_results_with_augmentation,clustering_2_results_with_augmentation)\n",
        "\n",
        "#Cats vs Dogs HDBSCAN\n",
        "db_3_with_augmentation = davies_bouldin_score(umap_catsvsdogs_train_results_with_augmentation,clustering_3_results_with_augmentation)\n",
        "db_4_with_augmentation = davies_bouldin_score(umap_catsvsdogs_test_results_with_augmentation,clustering_4_results_with_augmentation)\n",
        "\n",
        "\n",
        "#iRoads Agglomerative\n",
        "db_5_with_augmentation = davies_bouldin_score(umap_train_road_results_with_augmentation,algo_1_results_with_augmentation)\n",
        "db_6_with_augmentation = davies_bouldin_score(umap_test_road_results_with_augmentation,algo_2_results_with_augmentation)\n",
        "\n",
        "#Cats vs Dogs Agglomerative\n",
        "db_7_with_augmentation = davies_bouldin_score(umap_catsvsdogs_train_results_with_augmentation,algo_3_results_with_augmentation)\n",
        "db_8_with_augmentation = davies_bouldin_score(umap_catsvsdogs_test_results_with_augmentation,algo_4_results_with_augmentation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqzQz27ljvTn"
      },
      "outputs": [],
      "source": [
        "#Print Davis-Bouldin Values\n",
        "\n",
        "print(f\"HDBSCAN: iRoads train {db_1_with_augmentation}, test {db_2_with_augmentation},  CatsvsDogs train {db_3_with_augmentation}, test {db_4_with_augmentation}\")\n",
        "print(f\"Agglomerative : iRoads train {db_5_with_augmentation}, test {db_6_with_augmentation}, CatsvsDogs train {db_7_with_augmentation}, test {db_8_with_augmentation}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cr4lnGr48Y0"
      },
      "source": [
        "CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJyYOr7WFdXG"
      },
      "outputs": [],
      "source": [
        "#iRoads\n",
        "\n",
        "#XGBoost\n",
        "modelboost = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
        "modelboost.fit(road_train_scaled,y_trainr)\n",
        "boost_predict = modelboost.predict(road_test_scaled)\n",
        "\n",
        "#Evaluation of XGBoost\n",
        "reportboost = classification_report(y_testr, boost_predict)\n",
        "matrixboost = confusion_matrix(y_testr,boost_predict)\n",
        "accuracyboost = accuracy_score(y_testr,boost_predict)\n",
        "\n",
        "\n",
        "#SVM\n",
        "model1 = SVC(kernel=\"rbf\", random_state=23)\n",
        "model1.fit(road_train_scaled,y_trainr)\n",
        "prediction1 = model1.predict(road_test_scaled)\n",
        "\n",
        "#Evaluation of SVM\n",
        "report = classification_report(y_testr,prediction1)\n",
        "matrix = confusion_matrix(y_testr,prediction1)\n",
        "accuracy = accuracy_score(y_testr,prediction1)\n",
        "\n",
        "\n",
        "#MLP Classifier\n",
        "model2 = MLPClassifier(random_state=23, max_iter=300)\n",
        "model2.fit(road_train_scaled,y_trainr)\n",
        "prediction2 = model2.predict(road_test_scaled)\n",
        "\n",
        "#Evaluation of #MLP Classifier\n",
        "report2 = classification_report(y_testr, prediction2)\n",
        "matrix2 = confusion_matrix(y_testr,prediction2)\n",
        "accuracy2 = accuracy_score(y_testr,prediction2 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mx7kKtXvR5Xi"
      },
      "outputs": [],
      "source": [
        "#Print XGBoost Classifer Evaluation\n",
        "print(reportboost)\n",
        "print(matrixboost)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrixboost, annot=True, fmt=\"g\", cmap=\"Greens\", xticklabels=np.unique(y_testr), yticklabels=np.unique(y_testr))\n",
        "plt.title(\"XG Boost Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Print SVM Classifer  Evaluation\n",
        "print(reportboost)\n",
        "print(accuracyboost)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrix, annot=True, fmt=\"g\", cmap=\"Reds\", xticklabels=np.unique(y_testr), yticklabels=np.unique(y_testr))\n",
        "plt.title(\"SVM Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Print MLP Classifier Evaluation\n",
        "print(report2)\n",
        "print(accuracy2)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrix2, annot=True, fmt=\"g\", cmap=\"Blues\", xticklabels=np.unique(y_testr), yticklabels=np.unique(y_testr))\n",
        "plt.title(\"MLP Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PFAlVKfZVhdj"
      },
      "outputs": [],
      "source": [
        "#CatsvsDogs\n",
        "\n",
        "#Decision Tree\n",
        "model3 = DecisionTreeClassifier(max_depth=10, max_features=\"sqrt\", splitter=\"random\", random_state=23)\n",
        "model3.fit(catsvsdogs_train_scaled,y_train)\n",
        "prediction3 = model3.predict(catsvsdogs_test_scaled)\n",
        "\n",
        "#Evaluation of Decision Tree\n",
        "report3 = classification_report(y_test,prediction3)\n",
        "matrix3 = confusion_matrix(y_test,prediction3)\n",
        "accuracy3 = accuracy_score(y_test,prediction3)\n",
        "\n",
        "#MLP Classifier\n",
        "model4 = MLPClassifier(random_state=23, max_iter=300)\n",
        "model4.fit(catsvsdogs_train_scaled,y_train)\n",
        "prediction4 = model4.predict(catsvsdogs_test_scaled)\n",
        "\n",
        "#Evaluation of MLP Classifier\n",
        "report4 = classification_report(y_test,prediction4)\n",
        "matrix4 = confusion_matrix(y_test,prediction4)\n",
        "accuracy4 = accuracy_score(y_test,prediction4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IyF3I6ISnFki"
      },
      "outputs": [],
      "source": [
        "#Print Decision Tree Evaluation\n",
        "print(report3)\n",
        "print(accuracy3)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrix3, annot=True, fmt=\"g\", cmap=\"Reds\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.title(\"Decision Tree Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "#Print MLP Classifier Evaluation\n",
        "print(report4)\n",
        "print(accuracy4)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrix4, annot=True, fmt=\"g\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.title(\"MLP Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STLAkEGapWqX"
      },
      "source": [
        "Classification - augmentation included"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4XTW8M5pUfL"
      },
      "outputs": [],
      "source": [
        "#iRoads\n",
        "\n",
        "#XGBoost\n",
        "modelboost2 = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
        "modelboost2.fit(road_train_scaled_with_augmentation,y_trainr_a)\n",
        "boost_predict2 = modelboost2.predict(road_test_scaled_with_augmentation)\n",
        "\n",
        "#Evaluation of XGBoost\n",
        "reportboost2 = classification_report(y_testr_a, boost_predict2)\n",
        "matrixboost2 = confusion_matrix(y_testr_a,boost_predict2)\n",
        "accuracyboost2 = accuracy_score(y_testr_a,boost_predict2)\n",
        "\n",
        "\n",
        "#SVM\n",
        "model1_with_augmentation = SVC(kernel=\"rbf\", random_state=23)\n",
        "model1_with_augmentation.fit(road_train_scaled_with_augmentation,y_trainr_a)\n",
        "prediction1_with_augmentation = model1_with_augmentation.predict(road_test_scaled_with_augmentation)\n",
        "\n",
        "#Evaluation of SVM\n",
        "report_with_augmentation = classification_report(y_testr_a,prediction1_with_augmentation)\n",
        "matrix_with_augmentation = confusion_matrix(y_testr_a,prediction1_with_augmentation)\n",
        "accuracy_with_augmentation = accuracy_score(y_testr_a,prediction1_with_augmentation)\n",
        "\n",
        "\n",
        "#MLP Classifier\n",
        "model2_with_augmentation = MLPClassifier(random_state=23, max_iter=300)\n",
        "model2_with_augmentation.fit(road_train_scaled_with_augmentation,y_trainr_a)\n",
        "prediction2_with_augmentation = model2_with_augmentation.predict(road_test_scaled_with_augmentation)\n",
        "\n",
        "#Evaluation of #MLP Classifier\n",
        "report2_with_augmentation = classification_report(y_testr_a, prediction2_with_augmentation)\n",
        "matrix2_with_augmentation = confusion_matrix(y_testr_a,prediction2_with_augmentation)\n",
        "accuracy2_with_augmentation = accuracy_score(y_testr_a,prediction2_with_augmentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PTzCr9owqrsl"
      },
      "outputs": [],
      "source": [
        "#Print XGBoost Classifer Evaluation\n",
        "print(reportboost2)\n",
        "print(accuracyboost2)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrixboost2, annot=True, fmt=\"g\", cmap=\"Greens\", xticklabels=np.unique(y_testr_a), yticklabels=np.unique(y_testr_a))\n",
        "plt.title(\"XGBoost Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Print SVM Evaluation -\n",
        "print(report_with_augmentation)\n",
        "print(accuracy_with_augmentation)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrix_with_augmentation, annot=True, fmt=\"g\", cmap=\"Reds\", xticklabels=np.unique(y_testr_a), yticklabels=np.unique(y_testr_a))\n",
        "plt.title(\"SVM Classifier Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Print MLP Classifier Evaluation\n",
        "print(report2_with_augmentation)\n",
        "print(accuracy2_with_augmentation)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrix2_with_augmentation, annot=True, fmt=\"g\", cmap=\"Blues\", xticklabels=np.unique(y_testr_a), yticklabels=np.unique(y_testr_a))\n",
        "plt.title(\"MLP Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x35bd0gq0ZH"
      },
      "outputs": [],
      "source": [
        "#CatsvsDogs\n",
        "\n",
        "#Decision Tree\n",
        "model3_with_augmentation = DecisionTreeClassifier(max_depth=10, max_features=\"sqrt\", splitter=\"random\", random_state=23)\n",
        "model3_with_augmentation.fit(catsvsdogs_train_scaled_with_augmentation,y_train_a)\n",
        "prediction3_with_augmentation = model3_with_augmentation.predict(catsvsdogs_test_scaled_with_augmentation)\n",
        "\n",
        "#Evaluation of Decision Tree\n",
        "report3_with_augmentation = classification_report(y_test_a,prediction3_with_augmentation)\n",
        "matrix3_with_augmentation = confusion_matrix(y_test_a,prediction3_with_augmentation)\n",
        "accuracy3_with_augmentation = accuracy_score(y_test_a,prediction3_with_augmentation)\n",
        "\n",
        "#MLP Classifier\n",
        "model4_with_augmentation = MLPClassifier(random_state=23, max_iter=300)\n",
        "model4_with_augmentation.fit(catsvsdogs_train_scaled_with_augmentation,y_train_a)\n",
        "prediction4_with_augmentation = model4_with_augmentation.predict(catsvsdogs_test_scaled_with_augmentation)\n",
        "\n",
        "#Evaluation of MLP Classifier\n",
        "report4_with_augmentation = classification_report(y_test_a,prediction4_with_augmentation)\n",
        "matrix4_with_augmentation = confusion_matrix(y_test_a,prediction4_with_augmentation)\n",
        "accuracy4_with_augmentation = accuracy_score(y_test_a,prediction4_with_augmentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwtV_gnsrawj"
      },
      "outputs": [],
      "source": [
        "#Print Decision Tree Evaluation\n",
        "print(report3_with_augmentation)\n",
        "print(accuracy3_with_augmentation)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrix3_with_augmentation, annot=True, fmt=\"g\", cmap=\"Reds\", xticklabels=np.unique(y_test_a), yticklabels=np.unique(y_test_a))\n",
        "plt.title(\"Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Print MLP Classifier Evaluation\n",
        "print(report4_with_augmentation)\n",
        "print(accuracy4_with_augmentation)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(matrix4_with_augmentation, annot=True, fmt=\"g\", cmap=\"Blues\", xticklabels=np.unique(y_test_a), yticklabels=np.unique(y_test_a))\n",
        "plt.title(\"Confussion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
